{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализуем методы для наивного байеса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем выборку, в которой каждый признак имеет некоторое своё распределение, параметры которого отличаются для каждого класса. Затем реализуем несколько методов для класса, который уже частично написан ниже:\n",
    "- метод predict\n",
    "- метод \\_find\\_expon\\_params и \\_get\\_expon\\_density для экспоненциального распределения\n",
    "- метод \\_find\\_norm\\_params и \\_get\\_norm\\_probability для биномиального распределения\n",
    "\n",
    "Для имплементации \\_find\\_something\\_params изучите документацию функций для работы с этими распределениями в scipy.stats и используйте предоставленные там методы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем параметры генерации для трех датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 1), (5000,), ['bernoulli'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_params_set0 = [(scipy.stats.bernoulli, [dict(p=0.1), dict(p=0.5)]),\n",
    "                   ]\n",
    "\n",
    "func_params_set1 = [(scipy.stats.bernoulli, [dict(p=0.1), dict(p=0.5)]),\n",
    "                    (scipy.stats.expon, [dict(scale=1), dict(scale=0.3)]),\n",
    "                   ]\n",
    "\n",
    "func_params_set2 = [(scipy.stats.bernoulli, [dict(p=0.1), dict(p=0.5)]),\n",
    "                    (scipy.stats.expon, [dict(scale=1), dict(scale=0.3)]),\n",
    "                    (scipy.stats.norm, [dict(loc=0, scale=1), dict(loc=1, scale=2)]),\n",
    "                   ]\n",
    "\n",
    "def generate_dataset_for_nb(func_params_set=[], size = 2500, random_seed=0):\n",
    "    '''\n",
    "    Генерирует выборку с заданными параметрами распределений P(x|y).\n",
    "    Число классов задается длиной списка с параметрами.\n",
    "    Возвращает X, y, список с названиями распределений\n",
    "    '''\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    X = []\n",
    "    names = []\n",
    "    for func, params in func_params_set:\n",
    "        names.append(func.name)\n",
    "        f = []\n",
    "        for i, param in enumerate(params):\n",
    "            f.append(func.rvs(size=size, **param))\n",
    "        f = np.concatenate(f).reshape(-1,1)\n",
    "        X.append(f)\n",
    "\n",
    "    X = np.concatenate(X, 1)\n",
    "    y = np.array([0] * size + [1] * size)\n",
    "\n",
    "    shuffle_inds = np.random.choice(range(len(X)), size=len(X), replace=False)\n",
    "    X = X[shuffle_inds]\n",
    "    y = y[shuffle_inds]\n",
    "\n",
    "    return X, y, names \n",
    "\n",
    "X, y, distrubution_names = generate_dataset_for_nb(func_params_set0)\n",
    "X.shape, y.shape, distrubution_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class NaiveBayes(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "    Реализация наивного байеса, которая помимо X, y\n",
    "    принимает на вход во время обучения \n",
    "    виды распределений значений признаков\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def _find_bernoulli_params(self, x):\n",
    "        '''\n",
    "        метод возвращает найденный параметр `p`\n",
    "        распределения scipy.stats.bernoulli\n",
    "        '''\n",
    "        return dict(p=np.mean(x))\n",
    "    \n",
    "    def _get_bernoulli_probability(self, x, params):\n",
    "        '''\n",
    "        метод возвращает вероятность x для данных\n",
    "        параметров распределния\n",
    "        '''\n",
    "        return scipy.stats.bernoulli.pmf(x, **params)\n",
    "\n",
    "    def _find_expon_params(self, x):\n",
    "        # нужно определить параметры распределения\n",
    "        # и вернуть их\n",
    "        loc, scale = scipy.stats.expon.fit(x, floc=0)\n",
    "        return dict(scale=scale)\n",
    "    \n",
    "    def _get_expon_density(self, x, params):\n",
    "        # нужно вернуть плотность распределения в x\n",
    "        return scipy.stats.expon.pdf(x, **params)\n",
    "\n",
    "    def _find_norm_params(self, x):\n",
    "        # нужно определить параметры распределения\n",
    "        # и вернуть их\n",
    "        loc, scale = scipy.stats.norm.fit(x)\n",
    "        return dict(loc=loc, scale=scale)\n",
    "    \n",
    "    def _get_norm_density(self, x, params):\n",
    "        # нужно вернуть плотность распределения в x\n",
    "        return scipy.stats.norm.pdf(x, **params)\n",
    "\n",
    "    def _get_params(self, x, distribution):\n",
    "        '''\n",
    "        x - значения из распределения,\n",
    "        distribution - название распределения в scipy.stats\n",
    "        '''\n",
    "        if distribution == 'bernoulli':\n",
    "            return self._find_bernoulli_params(x)\n",
    "        elif distribution == 'expon':\n",
    "            return self._find_expon_params(x)\n",
    "        elif distribution == 'norm':\n",
    "            return self._find_norm_params(x)\n",
    "        else:\n",
    "            raise NotImplementedError('Unknown distribution')\n",
    "            \n",
    "    def _get_probability_or_density(self, x, distribution, params):\n",
    "        '''\n",
    "        x - значения,\n",
    "        distribution - название распределения в scipy.stats,\n",
    "        params - параметры распределения\n",
    "        '''\n",
    "        if distribution == 'bernoulli':\n",
    "            return self._get_bernoulli_probability(x, params)\n",
    "        elif distribution == 'expon':\n",
    "            return self._get_expon_density(x, params)\n",
    "        elif distribution == 'norm':\n",
    "            return self._get_norm_density(x, params)\n",
    "        else:\n",
    "            raise NotImplementedError('Unknown distribution')\n",
    "\n",
    "    def fit(self, X, y, distrubution_names):\n",
    "        '''\n",
    "        X - обучающая выборка,\n",
    "        y - целевая переменная,\n",
    "        feature_distributions - список названий распределений, \n",
    "        по которым предположительно распределны значения P(x|y)\n",
    "        ''' \n",
    "        assert X.shape[1] == len(distrubution_names)\n",
    "        assert set(y) == {0, 1}\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        self.distrubution_names = distrubution_names\n",
    "        \n",
    "        self.y_prior = [(y == j).mean() for j in range(self.n_classes)]\n",
    "        \n",
    "        self.y = y\n",
    "        self.distributions_params = defaultdict(dict)\n",
    "        for i in range(X.shape[1]):\n",
    "            distribution = self.distrubution_names[i]\n",
    "            for j in range(self.n_classes):\n",
    "                values = X[y == j, i]\n",
    "                self.distributions_params[j][i] = \\\n",
    "                    self._get_params(values, distribution)\n",
    "        \n",
    "        return self.distributions_params\n",
    "    \n",
    "    def get_p_x_c(self, x, c, feature):\n",
    "        #сколько всего меток класса с было\n",
    "        y = self.y\n",
    "        number_c = self.number_c_1\n",
    "        if (c == 0):\n",
    "            number_c = self.number_c_0\n",
    "        \n",
    "        number_x_and_c = 0\n",
    "        for i in range(len(feature)):\n",
    "            if (feature[i] == x and y[i] == c):\n",
    "                number_x_and_c += 1\n",
    "        return number_x_and_c / number_c\n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        X - тестовая выборка\n",
    "        '''\n",
    "        assert X.shape[1] == len(self.distrubution_names)\n",
    "        \n",
    "        # нужно реализовать подсчет аргмаксной формулы, по которой \n",
    "        # наивный байес принимает решение о принадлежности объекта классу\n",
    "        # и применить её для каждого объекта в X\n",
    "        #\n",
    "        # примечание: обычно подсчет этой формулы реализуют через \n",
    "        # её логарифмирование, то есть, через сумму логарифмов вероятностей, \n",
    "        # поскольку перемножение достаточно малых вероятностей будет вести\n",
    "        # к вычислительным неточностям\n",
    "        \n",
    "        probabl_classes_1 = []\n",
    "        probabl_classes_0 = []\n",
    "        \n",
    "        y = self.y\n",
    "        \n",
    "        self.number_c_1 = len([y[i] for i in range(len(y)) if (y[i] == 1)])\n",
    "        self.number_c_0 = len([y[i] for i in range(len(y)) if (y[i] == 0)])\n",
    "        \n",
    "        classes = np.unique(self.y_prior)\n",
    "        for i in range(len(X[0])):\n",
    "            cur_feature = list(X.T[i])\n",
    "            distribution = self.distrubution_names[i]\n",
    "            for j in range(len(cur_feature)):\n",
    "                #предсказываем для класса 1, если вероятность будет меньше, то вернем класс 0\n",
    "                x = cur_feature[j]\n",
    "                \n",
    "                #апостериорная вероятность класса (1\\0) для данного признака\n",
    "                p_x_c_1 = self.get_p_x_c(x, 1, cur_feature)\n",
    "                p_x_c_0 = self.get_p_x_c(x, 0, cur_feature)\n",
    "                \n",
    "                params = self._get_params(x, distribution)\n",
    "                p_x = self._get_probability_or_density(x, distribution, params)\n",
    "                \n",
    "                probabl_classes_1.append(np.log(p_x_c_1) - np.log(p_x))\n",
    "                probabl_classes_0.append(np.log(p_x_c_0) - np.log(p_x))\n",
    "            \n",
    "            \n",
    "        p_c_1 = self.number_c_1 / len(y)\n",
    "        p_c_0 = self.number_c_0 / len(y)\n",
    "        \n",
    "        class_1 = np.reshape(np.array(probabl_classes_1), (len(X[0]), 5000))\n",
    "        preds_1 = np.sum(class_1, axis=0) + np.log(p_c_1)\n",
    "        \n",
    "        class_0 = np.reshape(np.array(probabl_classes_0), (len(X[0]), 5000))\n",
    "        preds_0 = np.sum(class_0, axis=0) + np.log(p_c_0)\n",
    "        \n",
    "        c = np.concatenate(([preds_0], [preds_1]), axis=0)\n",
    "        preds = np.argmax(c, axis=0)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 7, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[2, 1, 6, 8], [1, 1, 1, 1]])\n",
    "np.sum(a, axis=0)\n",
    "#np.argmax(a, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[4 1 8]\n",
      "[[1 2 3]\n",
      " [4 1 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 1, 8])\n",
    "print(a)\n",
    "print(b)\n",
    "c = np.concatenate((a, b), axis=0)\n",
    "c = np.reshape(c, (2, 3))\n",
    "print(c)\n",
    "np.argmax(c, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  3, 11])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = np.sum(c, axis=0).T\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 5), (3, 3), (11, 11)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(list(k), list(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.concatenate(([k], [k]), axis=0)\n",
    "np.argmax(u, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  3, 11])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(c, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим результат на примере первого распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict, {0: {0: {'p': 0.1128}}, 1: {0: {'p': 0.482}}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = NaiveBayes()\n",
    "nb.fit(X, y, ['bernoulli'])\n",
    "#defaultdict(dict, {0: {0: {'p': 0.1128}}, 1: {0: {'p': 0.482}}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_1 = [[-0.65778004 -0.72981116 -0.65778004 ... -0.65778004 -0.72981116\n",
      "  -0.65778004]]\n",
      "sum = [-0.65778004 -0.72981116 -0.65778004 ... -0.65778004 -0.72981116\n",
      " -0.65778004]\n",
      "len preds_1 = 5000\n",
      "c = [[-0.81283202 -2.87528612 -0.81283202 ... -0.81283202 -2.87528612\n",
      "  -0.81283202]\n",
      " [-1.35092722 -1.42295835 -1.35092722 ... -1.35092722 -1.42295835\n",
      "  -1.35092722]]\n",
      "len c = 2\n",
      "len(preds) = 5000\n",
      "0.6045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "prediction = nb.predict(X)\n",
    "score = f1_score(y, prediction)\n",
    "print('{:.4f}'.format(score))\n",
    "#0.6045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответы для формы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответом для формы должны служить числа, которые будут выведены ниже. Все ответы проверены: в этих примерах получается одинаковый результат и через сумму логарифмов, и через произведение вероятностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " ...\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]], y = [1 0 0 ... 0 1 0], distrubution_names = ['bernoulli', 'bernoulli']\n",
      "class_1 = [[-0.65778004 -0.65778004 -0.65778004 ... -0.65778004 -0.72981116\n",
      "  -0.65778004]\n",
      " [-0.70360164 -0.68280089 -0.68280089 ... -0.70360164 -0.70360164\n",
      "  -0.68280089]]\n",
      "sum = [-1.36138168 -1.34058093 -1.34058093 ... -1.36138168 -1.4334128\n",
      " -1.34058093]\n",
      "len preds_1 = 5000\n",
      "c = [[-3.16041448 -0.91331556 -0.91331556 ... -3.16041448 -5.22286858\n",
      "  -0.91331556]\n",
      " [-2.05452886 -2.03372811 -2.03372811 ... -2.05452886 -2.12655998\n",
      "  -2.03372811]]\n",
      "len c = 2\n",
      "len(preds) = 5000\n",
      "0.7615\n",
      "X = [[0.         0.38970611]\n",
      " [0.         1.98976566]\n",
      " [0.         0.02420106]\n",
      " ...\n",
      " [0.         3.26481277]\n",
      " [1.         0.90650141]\n",
      " [0.         0.09442056]], y = [1 0 0 ... 0 1 0], distrubution_names = ['bernoulli', 'expon']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nadezhda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:166: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Nadezhda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:165: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_1 = [[-0.65778004 -0.65778004 -0.65778004 ... -0.65778004 -0.72981116\n",
      "  -0.65778004]\n",
      " [-7.76640839        -inf        -inf ...        -inf -6.92220871\n",
      "         -inf]]\n",
      "sum = [-8.42418842        -inf        -inf ...        -inf -7.65201987\n",
      "        -inf]\n",
      "len preds_1 = 5000\n",
      "c = [[        -inf  -6.94886116 -11.35823656 ...  -6.45367562         -inf\n",
      "   -9.99687443]\n",
      " [ -9.1173356          -inf         -inf ...         -inf  -8.34516705\n",
      "          -inf]]\n",
      "len c = 2\n",
      "len(preds) = 5000\n",
      "1.0000\n",
      "X = [[ 0.          0.07979793 -2.81833408]\n",
      " [ 1.          0.19636213  1.27899585]\n",
      " [ 1.          0.14832287 -0.60384868]\n",
      " ...\n",
      " [ 0.          0.8611044  -0.5600871 ]\n",
      " [ 0.          2.44201643  2.54627659]\n",
      " [ 0.          0.9297251   0.28562053]], y = [1 1 1 ... 0 1 0], distrubution_names = ['bernoulli', 'expon', 'norm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nadezhda\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1652: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  x = np.asarray((x - loc)/scale, dtype=dtyp)\n",
      "C:\\Users\\Nadezhda\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:876: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  return (self.a <= x) & (x <= self.b)\n",
      "C:\\Users\\Nadezhda\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:876: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return (self.a <= x) & (x <= self.b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_1 = [[-0.65778004 -0.72981116 -0.72981116 ... -0.65778004 -0.65778004\n",
      "  -0.65778004]\n",
      " [-9.35230374 -8.45184071 -8.73240984 ...        -inf -5.93122191\n",
      "         -inf]\n",
      " [        nan         nan         nan ...         nan         nan\n",
      "          nan]]\n",
      "sum = [nan nan nan ... nan nan nan]\n",
      "len preds_1 = 5000\n",
      "c = [[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n",
      "len c = 2\n",
      "len(preds) = 5000\n",
      "0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nadezhda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scipy.stats.bernoulli.name\n",
    "\n",
    "for fps in (func_params_set0 * 2,\n",
    "            func_params_set1, \n",
    "            func_params_set2):\n",
    "    \n",
    "\n",
    "    X, y, distrubution_names = generate_dataset_for_nb(fps)\n",
    "    print(f'X = {X}, y = {y}, distrubution_names = {distrubution_names}')\n",
    "    nb = NaiveBayes()\n",
    "    nb.fit(X, y, distrubution_names)\n",
    "    prediction = nb.predict(X)\n",
    "    #print(f'prediction = {prediction}')\n",
    "    score = f1_score(y, prediction)\n",
    "    print('{:.4f}'.format(score))\n",
    "    \n",
    "#0.7615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
